{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from csv file using pandas and excluding the values containing null values\n",
    "data_weather = pd.read_csv(\"Districtwise_India.csv\",sep=\"\\t\")\n",
    "df = data_weather[data_weather['Lat'].notna()]\n",
    "df.Lat = df.Lat.astype(str)\n",
    "df.Long = df.Long.astype(str)\n",
    "\n",
    "# Iterating in the rows of csv to get the latitude, longitude of the districts\n",
    "for index, row in df.iterrows():\n",
    "    his_data=[]\n",
    "    district = row['District']\n",
    "    days=5\n",
    "    lat= row['Lat']\n",
    "    lon= row['Long']\n",
    "    \n",
    "# This is an example of how the values could be of any specific place\n",
    "# district = 'Kolar'\n",
    "# days=5\n",
    "# lat='13.137'\n",
    "# lon='78.134'\n",
    "\n",
    "\n",
    "# To scrape the historical data, you need to provide the url parsed by bs4, number of days to get data\n",
    "    for i in range(days):\n",
    "    \td = date.today() - timedelta(i)\n",
    "    \tquote_page=\"https://darksky.net/details/\"+lat+','+lon+'/'+str(d)+\"/us12/en\"\n",
    "    \tpage = urlopen(quote_page)\n",
    "    \tsoup = BeautifulSoup(page, \"html.parser\")\n",
    "     \n",
    "     # components of weather to be extracted\n",
    "    \tprecipitation_box= soup.find(attrs={\"class\": \"precipProbability\"}).find(attrs={\"class\":\"num swip\"})\n",
    "    \train_box= soup.find(attrs={\"class\": \"precipAccum swap\"}).find(attrs={\"class\":\"num swip\"})\n",
    "    \ttemp_box = soup.find(attrs={\"class\": \"temperature\"}).find(attrs={\"class\":\"num\"})\n",
    "    \twind_box = soup.find(attrs={\"class\": \"wind\"}).find(attrs={\"class\":\"num swip\"})\n",
    "    \tpressure_box = soup.find(attrs={\"class\": \"pressure\"}).find(attrs={\"class\":\"num swip\"})\n",
    "    \thumidity_box = soup.find(attrs={\"class\": \"humidity\"}).find(attrs={\"class\":\"num swip\"})\n",
    "    \tdew_point_box = soup.find(attrs={\"class\": \"dew_point\"}).find(attrs={\"class\":\"num\"})\n",
    "    \thigh_point_box = soup.find(attrs={\"class\":\"highLowTemp swip\"}).find(attrs={\"class\": \"highTemp swip\"}).find(attrs={\"class\": \"temp\"})\n",
    "    \tlow_point_box = soup.find(attrs={\"class\":\"highLowTemp swip\"}).find(attrs={\"class\": \"lowTemp swap\"}).find(attrs={\"class\": \"temp\"})\n",
    "\n",
    "     # Storing the values in the list and using .text to extract the values\n",
    "    \tweather_components= [str(d),pressure_box.text,dew_point_box.text,humidity_box.text,temp_box.text,high_point_box.text.strip('/')[:2],low_point_box.text.strip('/')[:2],wind_box.text,precipitation_box.text,rain_box.text]\n",
    "     \n",
    "    # iterating through the list of items in weather_components to get the values and appending it to the empty list\n",
    "    \tfor i,val in enumerate(weather_components):\n",
    "    \t\tif val=='???' or val=='-':\n",
    "    \t\t   weather_components[i]= 'No Data Found'\n",
    "\n",
    "    \this_data.append(weather_components)\n",
    "    \tprint(weather_components)\n",
    "\n",
    "# To get the degree symbol in header row\n",
    "    a = u\"\\u00b0\"\n",
    "  \n",
    " # creating csv header for the file and appending the data in it using writerows\n",
    "    header = ['Date','Pressure(mb)',\"Dew Point(\"+a+')','Humidity(%)', 'Temperature('+a+')','Min Temp('+a+')','Max Temp('+a+')','Wind(mph)', 'Precipitation(%)', \"Rain(in)\"]\n",
    "\n",
    "    filename = district+'.csv'\n",
    "\n",
    "# Writing header, historical data of district in files using the filename\n",
    "    with open(filename, 'w') as myfile:\n",
    "        wr = csv.writer(myfile, lineterminator='\\n')\n",
    "        wr.writerow(header)\n",
    "        wr.writerows(his_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
